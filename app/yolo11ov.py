import cv2
import time
import random
import argparse
import numpy as np
import threading
import os
from openvino.runtime import Core

def load_source(source_file):
    img_formats = ['jpg', 'jpeg', 'png', 'tif', 'tiff', 'dng', 'webp', 'mpo']
    cap = None
    frame = None

    if source_file == "0" or source_file == 0:
        source_file = 0  # –í–µ–±-–∫–∞–º–µ—Ä–∞
        image_type = False
    else:
        image_type = source_file.split('.')[-1].lower() in img_formats

    if image_type:
        frame = cv2.imread(source_file)
        if frame is None:
            print(f"–ü–æ–º–∏–ª–∫–∞: –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è {source_file}")
            return True, None, None
    else:
        cap = cv2.VideoCapture(source_file)
        if not cap.isOpened():
            print(f"–ü–æ–º–∏–ª–∫–∞: –ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ –¥–∂–µ—Ä–µ–ª–æ –≤—ñ–¥–µ–æ {source_file}")
            return False, None, None

    return image_type, frame if image_type else None, cap

def preprocess_frame(frame, input_shape):
    """Preprocessing –¥–ª—è OpenVINO –º–æ–¥–µ–ª—ñ"""
    height, width = input_shape[2], input_shape[3]
    
    # –ó–º—ñ–Ω–∞ —Ä–æ–∑–º—ñ—Ä—É –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
    resized = cv2.resize(frame, (width, height))
    
    # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–æ —Ñ–æ—Ä–º–∞—Ç—É (1, 3, H, W) —Ç–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
    input_tensor = resized.transpose((2, 0, 1))  # HWC -> CHW
    input_tensor = input_tensor.astype(np.float32) / 255.0
    input_tensor = np.expand_dims(input_tensor, axis=0)  # –î–æ–¥–∞—Ç–∏ batch dimension
    
    return input_tensor

def postprocess_outputs(outputs, frame_shape, input_shape, conf_threshold=0.25):
    """–ü–æ—Å—Ç–æ–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ OpenVINO"""
    # –û—Ç—Ä–∏–º–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ (–ø—Ä–∏–ø—É—Å–∫–∞—î–º–æ —Ñ–æ—Ä–º–∞—Ç YOLO)
    predictions = outputs[0]  # –ü–µ—Ä—à–∏–π –≤–∏—Ö—ñ–¥
    
    # –Ø–∫—â–æ —Ñ–æ—Ä–º–∞ [1, 84, 8400] - —Ç—Ä–∞–Ω—Å–ø–æ–Ω—É–≤–∞—Ç–∏ –¥–æ [1, 8400, 84]
    if len(predictions.shape) == 3 and predictions.shape[1] < predictions.shape[2]:
        predictions = predictions.transpose((0, 2, 1))
    
    frame_height, frame_width = frame_shape[:2]
    input_height, input_width = input_shape[2], input_shape[3]
    
    # –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∏ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è
    x_factor = frame_width / input_width
    y_factor = frame_height / input_height
    
    boxes = []
    confidences = []
    class_ids = []
    
    for detection in predictions[0]:
        # –û—Ç—Ä–∏–º–∞—Ç–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ —Ü–µ–Ω—Ç—Ä—É —Ç–∞ —Ä–æ–∑–º—ñ—Ä–∏
        x, y, w, h = detection[:4]
        
        # –û—Ç—Ä–∏–º–∞—Ç–∏ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ –∫–ª–∞—Å—ñ–≤ (–ø–æ—á–∏–Ω–∞—é—á–∏ –∑ 4-–≥–æ –µ–ª–µ–º–µ–Ω—Ç–∞)
        class_scores = detection[4:]
        class_id = np.argmax(class_scores)
        confidence = class_scores[class_id]
        
        if confidence > conf_threshold:
            # –ü–µ—Ä–µ—Ç–≤–æ—Ä–∏—Ç–∏ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ñ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ –∫—É—Ç—ñ–≤
            left = int((x - w/2) * x_factor)
            top = int((y - h/2) * y_factor)
            width = int(w * x_factor)
            height = int(h * y_factor)
            
            boxes.append([left, top, width, height])
            confidences.append(float(confidence))
            class_ids.append(class_id)
    
    return boxes, confidences, class_ids

def yolo_detection_openvino(frame, compiled_model, input_layer, output_layer, NAMES, COLORS, args):
    """YOLO –¥–µ—Ç–µ–∫—Ü—ñ—è –∑ OpenVINO"""
    overlay = np.zeros_like(frame, dtype=np.uint8)
    
    # –û—Ç—Ä–∏–º–∞—Ç–∏ —Ñ–æ—Ä–º—É –≤—Ö–æ–¥—É
    input_shape = input_layer.shape
    
    # Preprocessing
    input_tensor = preprocess_frame(frame, input_shape)
    
    # –Ü–Ω—Ñ–µ—Ä–µ–Ω—Å
    results = compiled_model([input_tensor])
    
    # –ü–æ—Å—Ç–æ–±—Ä–æ–±–∫–∞
    boxes, confidences, class_ids = postprocess_outputs(
        results, frame.shape, input_shape, args.tresh
    )
    
    # Non-Maximum Suppression
    if boxes:
        indexes = cv2.dnn.NMSBoxes(boxes, confidences, args.tresh, 0.4)
    else:
        indexes = []
    
    current_frame_confidences = []
    
    if len(indexes) > 0:
        for i in indexes.flatten():
            left, top, width, height = boxes[i]
            class_id = class_ids[i]
            confidence = confidences[i]
            
            # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–∞–ª—ñ–¥–Ω–æ—Å—Ç—ñ class_id
            if 0 <= class_id < len(NAMES):
                color = COLORS[class_id]
                cv2.rectangle(overlay, (left, top), (left + width, top + height), color, args.thickness)
                text = f'{NAMES[class_id]} {confidence:.2f}'
                cv2.putText(overlay, text, (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                current_frame_confidences.append(confidence)
    
    avg_confidence_this_frame = np.mean(current_frame_confidences) if current_frame_confidences else 0.0
    return overlay, avg_confidence_this_frame

def benchmark_openvino_config(model_path, device="CPU", num_iterations=10):
    """–ë–µ–Ω—á–º–∞—Ä–∫ —Ç–µ—Å—Ç —Ä—ñ–∑–Ω–∏—Ö –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π OpenVINO"""
    print("\n" + "="*60)
    print("–ë–ï–ù–ß–ú–ê–†–ö –¢–ï–°–¢ OPENVINO –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–ô")
    print("="*60)
    
    # –¢–µ—Å—Ç–æ–≤–∏–π –≤—Ö—ñ–¥
    test_input = np.random.random((1, 3, 640, 640)).astype(np.float32)
    
    # –¢–µ—Å—Ç 1: –ë–µ–∑ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ–π
    print("üîÑ –¢–µ—Å—Ç 1: –ë–∞–∑–æ–≤–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è...")
    core1 = Core()
    model1 = core1.read_model(os.path.join(model_path, "yolo11n.xml"))
    compiled_model1 = core1.compile_model(model1, device)
    
    start_time = time.time()
    for _ in range(num_iterations):
        results = compiled_model1([test_input])
    base_time = time.time() - start_time
    print(f"‚è±Ô∏è –ë–∞–∑–æ–≤–∏–π —á–∞—Å: {base_time:.3f} —Å–µ–∫ ({base_time/num_iterations*1000:.1f} –º—Å/—ñ–Ω—Ñ–µ—Ä–µ–Ω—Å)")
    
    # –¢–µ—Å—Ç 2: –ó –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è–º–∏
    print("üîÑ –¢–µ—Å—Ç 2: –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è...")
    core2 = Core()
    model2 = core2.read_model(os.path.join(model_path, "yolo11n.xml"))
    
    # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –¥–ª—è ARM64
    optimized_config = {
        "CPU_THREADS_NUM": "4",
        "CPU_BIND_THREAD": "YES", 
        "CPU_THROUGHPUT_STREAMS": "4",
        "INFERENCE_NUM_THREADS": "4",
        "PERFORMANCE_HINT": "LATENCY"
    }
    
    # –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
    for key, value in optimized_config.items():
        try:
            core2.set_property("CPU", {key: value})
        except:
            pass
    
    compiled_model2 = core2.compile_model(model2, device, optimized_config)
    
    start_time = time.time()
    for _ in range(num_iterations):
        results = compiled_model2([test_input])
    optimized_time = time.time() - start_time
    print(f"‚è±Ô∏è –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π —á–∞—Å: {optimized_time:.3f} —Å–µ–∫ ({optimized_time/num_iterations*1000:.1f} –º—Å/—ñ–Ω—Ñ–µ—Ä–µ–Ω—Å)")
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç–∏
    improvement = ((base_time - optimized_time) / base_time) * 100
    print(f"üìà –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ: {improvement:.1f}%")
    if improvement > 0:
        print("‚úÖ –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –ø—Ä–∞—Ü—é—é—Ç—å!")
    else:
        print("‚ö†Ô∏è –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –Ω–µ –¥–∞–ª–∏ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è")
    print("="*60)
    
    return improvement


    global latest_frame, processed_overlay, processing_fps, total_detected_confidences, detected_frames_count
    frame_count = 0
    start_processing_time = time.time()

    while True:
        if latest_frame is not None:
            current_frame_to_process = latest_frame.copy()
            if current_frame_to_process is not None:
                overlay, avg_confidence_this_frame = yolo_detection_openvino(
                    current_frame_to_process, compiled_model_ref, input_layer_ref, 
                    output_layer_ref, NAMES_ref, COLORS_ref, args_ref
                )
                processed_overlay = overlay
                
                if avg_confidence_this_frame > 0:
                    total_detected_confidences += avg_confidence_this_frame
                    detected_frames_count += 1

                frame_count += 1

                elapsed_processing_time = time.time() - start_processing_time
                if elapsed_processing_time >= 1.0:
                    processing_fps = frame_count / elapsed_processing_time
                    frame_count = 0
                    start_processing_time = time.time()
        else:
            time.sleep(0.01)

if __name__ == '__main__':
    overall_start_time = time.time()

    parser = argparse.ArgumentParser()
    parser.add_argument("--source", type=str, default="data/videos/idiots3.mp4", help="–í—ñ–¥–µ–æ –∞–±–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è. '0' –¥–ª—è –≤–µ–±-–∫–∞–º–µ—Ä–∏.")
    parser.add_argument("--names", type=str, default="data/class.names", help="–®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É —ñ–º–µ–Ω –∫–ª–∞—Å—ñ–≤.")
    parser.add_argument("--model", type=str, default="yolo11n_openvino_model", help="–®–ª—è—Ö –¥–æ OpenVINO –º–æ–¥–µ–ª—ñ (–ø–∞–ø–∫–∞).")
    parser.add_argument("--tresh", type=float, default=0.25, help="–ü–æ—Ä—ñ–≥ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ –¥–ª—è –¥–µ—Ç–µ–∫—Ü—ñ—ó.")
    parser.add_argument("--thickness", type=int, default=2, help="–¢–æ–≤—â–∏–Ω–∞ —Ä–∞–º–∫–∏.")
    parser.add_argument("--device", type=str, default="AUTO", help="–ü—Ä–∏—Å—Ç—Ä—ñ–π OpenVINO (AUTO, CPU, GPU).")
    parser.add_argument("--benchmark", action="store_true", help="–ó–∞–ø—É—Å—Ç–∏—Ç–∏ –±–µ–Ω—á–º–∞—Ä–∫ —Ç–µ—Å—Ç –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ–π.")
    args = parser.parse_args()

    # –Ø–∫—â–æ –∑–∞–ø—Ä–æ—à–µ–Ω–æ –±–µ–Ω—á–º–∞—Ä–∫
    if args.benchmark:
        benchmark_openvino_config(args.model, args.device)
        exit()

    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è OpenVINO
    try:
        print("–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è OpenVINO...")
        core = Core()
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –ø—Ä–∏—Å—Ç—Ä–æ—ó–≤
        available_devices = core.available_devices
        print(f"–î–æ—Å—Ç—É–ø–Ω—ñ –ø—Ä–∏—Å—Ç—Ä–æ—ó: {available_devices}")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        model_xml = os.path.join(args.model, "yolo11n.xml")
        if not os.path.exists(model_xml):
            print(f"–ü–æ–º–∏–ª–∫–∞: –§–∞–π–ª –º–æ–¥–µ–ª—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {model_xml}")
            print("–ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—è, —â–æ –º–æ–¥–µ–ª—å –µ–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–∞ –≤ —Ñ–æ—Ä–º–∞—Ç OpenVINO")
            print("–û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ñ–∞–π–ª: yolo11n.xml")
            exit()
            
        model = core.read_model(model_xml)
        
        # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –¥–ª—è ARM64 (Radxa Zero 3E)
        config = {}
        if args.device == "CPU" or args.device == "AUTO":
            print("–ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ–π –¥–ª—è ARM64 CPU...")
            config = {
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –≤—Å—ñ 4 —è–¥—Ä–∞ RK3566
                "CPU_THREADS_NUM": "4",
                "CPU_BIND_THREAD": "YES",
                "CPU_THROUGHPUT_STREAMS": "4",
                # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –¥–ª—è ARM Cortex-A55
                "INFERENCE_NUM_THREADS": "4",
                "INFERENCE_PRECISION_HINT": "f32",
                # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
                "PERFORMANCE_HINT": "LATENCY",  # –∞–±–æ "THROUGHPUT"
                "EXECUTION_MODE_HINT": "PERFORMANCE"
            }
            
            # –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –≤–ª–∞—Å—Ç–∏–≤–æ—Å—Ç—ñ –¥–ª—è CPU
            for key, value in config.items():
                try:
                    core.set_property("CPU", {key: value})
                    print(f"‚úÖ {key}: {value}")
                except Exception as e:
                    print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –≤—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ {key}: {e}")
        
        compiled_model = core.compile_model(model, args.device, config)
        
        # –û—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –≤—Ö–æ–¥–∏ —Ç–∞ –≤–∏—Ö–æ–¥–∏
        input_layer = compiled_model.input(0)
        output_layer = compiled_model.output(0)
        
        print(f"–ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –Ω–∞ –ø—Ä–∏—Å—Ç—Ä—ñ–π: {args.device}")
        print(f"–§–æ—Ä–º–∞ –≤—Ö–æ–¥—É: {input_layer.shape}")
        print(f"–§–æ—Ä–º–∞ –≤–∏—Ö–æ–¥—É: {output_layer.shape}")
        
        # –í–∏–≤–µ–¥–µ–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω—ñ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        if args.device == "CPU" or args.device == "AUTO":
            try:
                actual_threads = core.get_property("CPU", "CPU_THREADS_NUM")
                print(f"‚úÖ –§–∞–∫—Ç–∏—á–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ—Ç–æ–∫—ñ–≤ CPU: {actual_threads}")
            except:
                print("‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Ç–æ–∫–∏ CPU")
                
            try:
                streams = core.get_property("CPU", "CPU_THROUGHPUT_STREAMS")
                print(f"‚úÖ –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ—Ç–æ–∫—ñ–≤ throughput: {streams}")
            except:
                print("‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ throughput streams")
        
        print("="*50)
        
    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó OpenVINO: {e}")
        exit()

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ–º–µ–Ω –∫–ª–∞—Å—ñ–≤
    try:
        with open(args.names, "r", encoding='utf-8') as f:
            NAMES = [cname.strip() for cname in f.readlines()]
    except FileNotFoundError:
        print(f"–ü–æ–º–∏–ª–∫–∞: –§–∞–π–ª —ñ–º–µ–Ω –∫–ª–∞—Å—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º {args.names}")
        print("–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏—Ö —ñ–º–µ–Ω –∫–ª–∞—Å—ñ–≤ COCO —è–∫ —Ä–µ–∑–µ—Ä–≤–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç.")
        NAMES = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
            'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
            'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
            'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',
            'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',
            'scissors', 'teddy bear', 'hair drier', 'toothbrush'
        ]
    
    COLORS = [[random.randint(0, 255) for _ in range(3)] for _ in NAMES]

    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∂–µ—Ä–µ–ª–∞
    image_type, initial_frame, cap = load_source(args.source)

    if initial_frame is None and cap is None:
        print("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∂–µ—Ä–µ–ª–æ. –í–∏—Ö—ñ–¥.")
        exit()

    # –ì–ª–æ–±–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–Ω—ñ
    latest_frame, processed_overlay = None, None
    processing_fps = 0.0
    total_detected_confidences = 0.0
    detected_frames_count = 0

    # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫—É –æ–±—Ä–æ–±–∫–∏
    processing_thread = threading.Thread(
        target=async_yolo_processing,
        args=(compiled_model, input_layer, output_layer, NAMES, COLORS, args),
        daemon=True
    )
    processing_thread.start()

    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –±–µ–Ω—á–º–∞—Ä–∫—É
    benchmark_results = {
        "source_file": args.source,
        "model_path": args.model,
        "device": args.device,
        "confidence_threshold": args.tresh,
        "input_image_size": f"{input_layer.shape[2]}x{input_layer.shape[3]}",
        "total_runtime_seconds": 0.0,
        "average_detection_fps": 0.0,
        "average_display_fps": 0.0,
        "source_fps": 0.0,
        "overall_average_confidence": 0.0,
        "available_devices": str(available_devices)
    }

    total_frames_read = 0
    display_start_time = time.time()
    total_display_frames = 0

    # –û–±—Ä–æ–±–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∞–±–æ –≤—ñ–¥–µ–æ
    if image_type:
        if initial_frame is not None:
            latest_frame = initial_frame.copy()
            print("–û–±—Ä–æ–±–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è...")
            while processed_overlay is None and processing_thread.is_alive():
                time.sleep(0.01)

            if processed_overlay is not None:
                result = cv2.addWeighted(initial_frame, 1.0, processed_overlay, 1.0, 0)
                cv2.imshow("OpenVINO YOLO Detection", result)
                output_filename = "output_openvino_" + os.path.basename(args.source)
                try:
                    cv2.imwrite(output_filename, result)
                    print(f"–û–±—Ä–æ–±–ª–µ–Ω–æ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —è–∫ {output_filename}")
                except Exception as e:
                    print(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {e}")
                cv2.waitKey(0)
            else:
                print("–û–±—Ä–æ–±–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –≤–¥–∞–ª–∞—Å—è.")
            
            total_frames_read = 1
            total_display_frames = 1
            if detected_frames_count > 0:
                 benchmark_results["overall_average_confidence"] = total_detected_confidences / detected_frames_count
        else:
            print("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –±—É–ª–æ None, –Ω–µ–º–æ–∂–ª–∏–≤–æ –æ–±—Ä–æ–±–∏—Ç–∏.")
    else:
        if cap is None or not cap.isOpened():
            print("–ó–∞—Ö–æ–ø–ª–µ–Ω–Ω—è –≤—ñ–¥–µ–æ –Ω–µ –≤—ñ–¥–∫—Ä–∏—Ç–æ. –í–∏—Ö—ñ–¥.")
            exit()

        video_fps = cap.get(cv2.CAP_PROP_FPS)
        benchmark_results["source_fps"] = video_fps
        frame_time = 1 / video_fps if video_fps > 0 else 0

        print(f"–û–±—Ä–æ–±–∫–∞ –≤—ñ–¥–µ–æ (FPS: {video_fps:.2f})...")
        print("–ù–∞—Ç–∏—Å–Ω—ñ—Ç—å 'q' –¥–ª—è –≤–∏—Ö–æ–¥—É")

        while True:
            start_frame_time = time.time()

            ret, frame = cap.read()
            if not ret:
                print("–ö—ñ–Ω–µ—Ü—å –≤—ñ–¥–µ–æ –ø–æ—Ç–æ–∫—É –∞–±–æ –Ω–µ–º–æ–∂–ª–∏–≤–æ –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ –∫–∞–¥—Ä.")
                break

            total_frames_read += 1
            latest_frame = frame.copy()
            
            overlay = processed_overlay if processed_overlay is not None else np.zeros_like(frame, dtype=np.uint8)
            result = cv2.addWeighted(frame, 1.0, overlay, 1.0, 0)
            total_display_frames += 1

            # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è FPS —Ç–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –ø—Ä–∏—Å—Ç—Ä—ñ–π
            fps_text = f"Video FPS: {video_fps:.2f} | Detection FPS: {processing_fps:.2f} | Device: {args.device}"
            cv2.putText(result, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # –î–æ–¥–∞—Ç–∫–æ–≤–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è
            info_text = f"Frames: {total_frames_read} | Detections: {detected_frames_count}"
            cv2.putText(result, info_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            cv2.imshow("OpenVINO YOLO Detection", result)

            elapsed_time = time.time() - start_frame_time
            sleep_time = max(frame_time - elapsed_time, 0)
            time.sleep(sleep_time)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        if total_display_frames > 0:
            benchmark_results["average_display_fps"] = total_display_frames / (time.time() - display_start_time)
        if detected_frames_count > 0:
            benchmark_results["overall_average_confidence"] = total_detected_confidences / detected_frames_count

    # –ó–∞–∫—Ä–∏—Ç—Ç—è —Ä–µ—Å—É—Ä—Å—ñ–≤
    if cap is not None:
        cap.release()
    cv2.destroyAllWindows()
    latest_frame = None

    # –§—ñ–Ω–∞–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    overall_end_time = time.time()
    benchmark_results["total_runtime_seconds"] = overall_end_time - overall_start_time
    benchmark_results["average_detection_fps"] = processing_fps

    # –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –±–µ–Ω—á–º–∞—Ä–∫—É
    print("\n" + "="*40)
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –±–µ–Ω—á–º–∞—Ä–∫—É OpenVINO:")
    print("="*40)
    for key, value in benchmark_results.items():
        print(f"{key.replace('_', ' ').capitalize()}: {value}")
    print("="*40)